{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport torch\nimport torchvision\nimport PIL\nfrom PIL import Image\nPIL.Image.MAX_IMAGE_PIXELS = None # allows big images\nfrom torchvision import transforms, models\nfrom torch.utils.data import Dataset\nfrom torchvision.utils import make_grid\nfrom matplotlib import pyplot as plt\nimport gc\nfrom tqdm import tqdm\nfrom typing import Optional, List, Dict","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-11T11:02:20.527606Z","iopub.execute_input":"2022-08-11T11:02:20.528283Z","iopub.status.idle":"2022-08-11T11:02:20.537023Z","shell.execute_reply.started":"2022-08-11T11:02:20.528235Z","shell.execute_reply":"2022-08-11T11:02:20.535531Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"# Loading the data","metadata":{}},{"cell_type":"code","source":"fileNames = []\nfilePaths = []\nfor dirname, _, filenames in os.walk('../input/mayo-clinic-strip-ai'):\n    for filename in filenames:\n        filePaths.append(os.path.join(dirname, filename))\n        fileNames.append(filename)\ndictFiles = {k:v for k,v in zip(fileNames,filePaths)}\ndfTrain = pd.read_csv(filePaths[1])\ndfTest = pd.read_csv(filePaths[2])\ndfTrain['paths'] = dfTrain.apply(lambda x: dictFiles[x['image_id']+'.tif'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:31:29.837437Z","iopub.execute_input":"2022-08-11T10:31:29.838248Z","iopub.status.idle":"2022-08-11T10:31:29.873636Z","shell.execute_reply.started":"2022-08-11T10:31:29.838196Z","shell.execute_reply":"2022-08-11T10:31:29.872688Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Direct approach","metadata":{}},{"cell_type":"code","source":"class MayoDataset(Dataset):\n    def __init__(self,dataframe,colPaths,colLabels, transform = None, label_transform = None):\n        self.dataframe = dataframe\n        self.colPaths = colPaths\n        self.colLabels = colLabels\n        self.transform = transform\n        self.label_transform = label_transform\n        \n    def __len__(self):\n        return len(self.dataframe)\n    \n    def __getitem__(self, index):\n        imagePath = self.dataframe[self.colPaths].iloc[index]\n        im = Image.open(imagePath)\n        label = self.dataframe[self.colLabels].iloc[index]\n        if self.transform:\n            im = self.transform(im)\n        if self.label_transform:\n            label = self.target_transform(imageLabel)\n            \n        return(im, label)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-08-10T15:32:23.463742Z","iopub.execute_input":"2022-08-10T15:32:23.464367Z","iopub.status.idle":"2022-08-10T15:32:23.471250Z","shell.execute_reply.started":"2022-08-10T15:32:23.464335Z","shell.execute_reply":"2022-08-10T15:32:23.470398Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"batch_size = 10\ntransform = transforms.Compose([\n                        transforms.Resize(224),\n                        transforms.RandomHorizontalFlip(p=0.5),\n                        transforms.RandomRotation(30),     \n                        transforms.CenterCrop(224),\n                        transforms.ToTensor()\n                        ])\n\n\ntrainData = MayoDataset(dfTrain , 'paths' , 'label' ,transform = transform)\ntrain_DataLoader = torch.utils.data.DataLoader(trainData, batch_size = batch_size , shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2022-08-10T15:32:26.101239Z","iopub.execute_input":"2022-08-10T15:32:26.102199Z","iopub.status.idle":"2022-08-10T15:32:26.108708Z","shell.execute_reply.started":"2022-08-10T15:32:26.102162Z","shell.execute_reply":"2022-08-10T15:32:26.107384Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"for images, labels in train_DataLoader:\n    break\nlabels\n\n","metadata":{"execution":{"iopub.status.busy":"2022-08-10T15:32:29.939431Z","iopub.execute_input":"2022-08-10T15:32:29.940423Z","iopub.status.idle":"2022-08-10T15:35:13.881655Z","shell.execute_reply.started":"2022-08-10T15:32:29.940382Z","shell.execute_reply":"2022-08-10T15:35:13.880750Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"im = make_grid(images,nrow = 5)\nplt.figure(figsize =(10,4))\nplt.imshow(np.transpose(im.numpy(),(1,2,0)))","metadata":{"execution":{"iopub.status.busy":"2022-08-10T15:35:52.197750Z","iopub.execute_input":"2022-08-10T15:35:52.198158Z","iopub.status.idle":"2022-08-10T15:35:52.493835Z","shell.execute_reply.started":"2022-08-10T15:35:52.198129Z","shell.execute_reply":"2022-08-10T15:35:52.492681Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"* Some images seems to be empty","metadata":{}},{"cell_type":"markdown","source":"## Undirect approach","metadata":{}},{"cell_type":"markdown","source":"* The directories are created","metadata":{}},{"cell_type":"code","source":"dirsToCreate = ['CE','LAA']\nparentDir = \"/kaggle/working\"\n\nfor newdir in dirsToCreate:\n    path = os.path.join(parentDir, newdir)\n    if  os.path.isdir(path) == False:\n        os.mkdir(path)","metadata":{"execution":{"iopub.status.busy":"2022-08-11T10:31:41.575548Z","iopub.execute_input":"2022-08-11T10:31:41.576022Z","iopub.status.idle":"2022-08-11T10:31:41.583276Z","shell.execute_reply.started":"2022-08-11T10:31:41.575980Z","shell.execute_reply":"2022-08-11T10:31:41.581951Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\ndef scaleKeepingAspectRatio(imSize:tuple,maxdim:int)->tuple:\n    '''\n    Takes the image size and calculates the new size keeping the aspect ratio constant and using as reference the heighest dimension\n    '''\n    maxdim = maxdim\n    dimns = list(imSize)\n    dimnsScaled = dimns.copy()\n    indxmindim = np.argmin(dimns)\n    indxmaxdim = np.argmax(dimns)\n    dimnsScaled[indxmaxdim] = maxdim\n    scaleFactor = maxdim/dimns[indxmaxdim]\n    dimnsScaled[indxmindim] = int(dimnsScaled[indxmindim]*scaleFactor)\n    return tuple(dimnsScaled)\n\n\nfor n, row in tqdm(dfTrain.iterrows()):\n    imName = row['image_id']\n    im = Image.open(row['paths'])\n    label = row['label']        \n    newSize = scaleKeepingAspectRatio(im.size,1024)\n    im = im.resize(newSize)\n    path = os.path.join(parentDir, label,imName)\n    im.save(path,'png')\n    del im # delete image\n    gc.collect() # release memory\n","metadata":{"execution":{"iopub.status.busy":"2022-08-11T11:06:26.159442Z","iopub.execute_input":"2022-08-11T11:06:26.160169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('images', 'zip', '/kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2022-08-11T06:52:43.268911Z","iopub.execute_input":"2022-08-11T06:52:43.269379Z","iopub.status.idle":"2022-08-11T06:52:48.243647Z","shell.execute_reply.started":"2022-08-11T06:52:43.269336Z","shell.execute_reply":"2022-08-11T06:52:48.241479Z"},"trusted":true},"execution_count":7,"outputs":[]}]}